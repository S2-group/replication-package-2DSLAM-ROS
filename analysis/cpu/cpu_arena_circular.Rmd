---
title: "CPU analysis - Circular arena"
output: html_notebook
---

```{r}
library(tidyverse)
library(ggpubr)
library(rstatix)
library(lmPerm)
library(e1071)
library(DescTools)

capitalize <- function(string) {
  substr(string, 1, 1) <- toupper(substr(string, 1, 1))
  string
}
custom_theme <- theme_bw(base_size = 19) + theme(
  axis.line = element_line(colour = "black"),
  panel.border = element_blank(),
  legend.position = "top",
  text=element_text(family="serif"),
)
```

# Measurements
Let us first load all measurements obtained from the experiment.

```{r}
measurements <- read.csv("/home/engel/Documents/experiments/slam_experiment/run_table.csv")
measurements <- measurements[measurements$arena == 'circular', ]
measurements$algorithm <- as.factor(measurements$algorithm)
measurements$map_resolution <- as.factor(measurements$map_resolution)
measurements$linear_update <- as.factor(measurements$linear_update)
measurements$angular_update <- as.factor(measurements$angular_update)
measurements
```

# Data exploration
```{r}
measurements %>%
  group_by(algorithm, map_resolution, linear_update, angular_update) %>%
  get_summary_stats(avg_cpu, type = "full")

measurements %>%
  group_by(algorithm) %>%
  get_summary_stats(avg_cpu, type = "full")
```

```{r}
hist <- gghistogram(measurements, x = "avg_cpu", color = "algorithm", fill = "algorithm", palette='jco') + custom_theme + xlab('CPU Utilisation (%)') + ylab('Count') + labs(color='Algorithm', fill='Algorithm') 
hist
ggexport(hist, filename = "cpu_circular_histogram.pdf")
```

```{r}
bxp <- ggboxplot(measurements, x = "map_resolution", y = "avg_cpu", palette = "jco", color="algorithm", facet.by = c("linear_update", "angular_update"), labeller="label_both") + theme_bw(base_size = 19) + theme(legend.position="top", text=element_text(family="serif")) + xlab('Map resolution') + ylab('CPU Utilisation (%)') + labs(color='Algorithm', fill='Algorithm')
bxp
ggexport(bxp, filename = "cpu_circular_box.pdf")
```
# ANOVA

## Assumption checking
ANOVA has four assumptions, which are checked in this section.

### 1. Independence of samples
By the design of the experiment, samples are independent (and fully randomised).

### 2. Normality of residuals
We fit a model based on all four factors (and their interactions) as parameters.
```{r}
model  <- lm(avg_cpu ~ algorithm*map_resolution*linear_update*angular_update, data = measurements)
res <- residuals(model)
```

Get an impression of the distribution of the residuals
```{r}
gghistogram(res, fill="lightgrey")
ggdensity(res, fill="lightgrey")

# Create a QQ plot of residuals
ggqqplot(res)
# Compute Shapiro-Wilk test of normality
shapiro_test(res)
skewness(res)
```
Not normal due to outliers. Trying some transformations found that reciprocal transform gives a normal result:
```{r}
measurements$avg_cpu_transformed <- 1 / measurements$avg_cpu
model  <- lm(avg_cpu_transformed ~ algorithm*map_resolution*linear_update*angular_update, data = measurements)
res <- residuals(model)
```

Get an impression of the distribution of the residuals
```{r}
gghistogram(res, fill="lightgrey")
ggdensity(res, fill="lightgrey")

# Create a QQ plot of residuals
ggqqplot(res)
# Compute Shapiro-Wilk test of normality
shapiro_test(res)
skewness(res)
```

### 3. Normality within groups
#### Transformed data
```{r}
shapiro_tests <- measurements %>% group_by(algorithm, map_resolution, linear_update, angular_update)  %>% shapiro_test(avg_cpu_transformed)
shapiro_tests[order(shapiro_tests$p),]
```

28 out of 32 groups have a p-value above 0.05, so for these we cannot reject H0 (the data is normally distributed). Checking the qq plots in addition.

```{r}
ggqqplot(measurements[measurements$algorithm == 'cartographer', ], "avg_cpu_transformed", ggtheme = theme_bw()) + facet_grid( linear_update + angular_update ~ map_resolution, labeller = "label_both")
ggqqplot(measurements[measurements$algorithm == 'gmapping', ], "avg_cpu_transformed", ggtheme = theme_bw()) + facet_grid(linear_update + angular_update ~ map_resolution, labeller = "label_both")
ggqqplot(measurements[measurements$algorithm == 'hector', ], "avg_cpu_transformed", ggtheme = theme_bw()) + facet_grid(linear_update + angular_update ~ map_resolution, labeller = "label_both")
ggqqplot(measurements[measurements$algorithm == 'karto', ], "avg_cpu_transformed", ggtheme = theme_bw()) + facet_grid(linear_update + angular_update ~ map_resolution, labeller = "label_both")
```
In the plots above, most points are around the normal line.  The normality assumption is therefore met.

#### Original data
```{r}
shapiro_tests <- measurements %>% group_by(algorithm, map_resolution, linear_update, angular_update)  %>% shapiro_test(avg_cpu)
shapiro_tests[order(shapiro_tests$p),]
```

29 out of 32 groups have a p-value above 0.05, so for these we cannot reject H0 (the data is normally distributed). Checking the qq plots in addition.

```{r}
ggqqplot(measurements[measurements$algorithm == 'cartographer', ], "avg_cpu", ggtheme = theme_bw()) + facet_grid( linear_update + angular_update ~ map_resolution, labeller = "label_both")
ggqqplot(measurements[measurements$algorithm == 'gmapping', ], "avg_cpu", ggtheme = theme_bw()) + facet_grid(linear_update + angular_update ~ map_resolution, labeller = "label_both")
ggqqplot(measurements[measurements$algorithm == 'hector', ], "avg_cpu", ggtheme = theme_bw()) + facet_grid(linear_update + angular_update ~ map_resolution, labeller = "label_both")
ggqqplot(measurements[measurements$algorithm == 'karto', ], "avg_cpu", ggtheme = theme_bw()) + facet_grid(linear_update + angular_update ~ map_resolution, labeller = "label_both")
```
In the plots above, most points are around the normal line.  The normality assumption is therefore met.

### 4. Homogeneity of variance
#### Transformed data
```{r}
levene_test(avg_cpu_transformed ~ algorithm*map_resolution*angular_update*linear_update, data = measurements)
```
The p-value is lower than 0.05, hence we reject H0. Thus, we cannot assume homogeneity of variance among all groups.

```{r}
agg_measurements <- measurements %>% group_by(algorithm, map_resolution, linear_update, angular_update) %>%
  get_summary_stats(avg_cpu_transformed, type = "mean_sd")
ggscatter(agg_measurements, "mean", "sd")
agg_measurements[order(agg_measurements$sd),]
```
#### Original data
```{r}
levene_test(avg_cpu ~ algorithm*map_resolution*angular_update*linear_update, data = measurements)
```
The p-value is lower than 0.05, hence we reject H0. Thus, we cannot assume homogeneity of variance among all groups.

This is also clearly visible when plotting the data: one group has an extremely high variance (exceeding 3x the other variances).

```{r}
agg_measurements <- measurements %>% group_by(algorithm, map_resolution, linear_update, angular_update) %>%
  get_summary_stats(avg_cpu, type = "mean_sd")
ggscatter(agg_measurements, "mean", "sd")
agg_measurements[order(agg_measurements$sd),]
```

## Running (PERM)ANOVA

```{r}
aov.out <- aov(avg_cpu_transformed ~ algorithm*map_resolution*linear_update*angular_update, data=measurements)
summary(aov.out)
```

### Post hoc tests

#### Algorithhm / Angular update
To analyse the effect of the algorithm and angular update interaction, we first assess normality of the groups and compare their variance.

```{r}
gghistogram(measurements, 'avg_cpu_transformed', color="algorithm", fill="algorithm") + custom_theme

shapiro_tests <- measurements %>% group_by(algorithm, angular_update)  %>% shapiro_test(avg_cpu_transformed)
shapiro_tests[order(shapiro_tests$p),]
```

```{r}
ggqqplot(measurements, "avg_cpu_transformed", ggtheme = theme_bw()) + facet_grid( angular_update ~ algorithm, labeller = "label_both")
```

```{r}
levene_test(avg_cpu_transformed ~ algorithm : angular_update, data = measurements)
```
The assumptions for Tukey's HSB test are not met. Hence, we resort to the non-parametric Dunn test.

```{r}
algorithm_angular_update_interaction <- interaction(measurements$algorithm, measurements$angular_update)
DunnTest(avg_cpu_transformed ~ algorithm_angular_update_interaction, measurements, method='BH')
```

#### Algorithhm / Linear update
To analyse the effect of the algorithm and linear update interaction, we first assess normality of the groups and compare their variance.

```{r}
gghistogram(measurements, 'avg_cpu_transformed', color="algorithm", fill="algorithm") + custom_theme

shapiro_tests <- measurements %>% group_by(algorithm, linear_update)  %>% shapiro_test(avg_cpu_transformed)
shapiro_tests[order(shapiro_tests$p),]
```

```{r}
ggqqplot(measurements, "avg_cpu_transformed", ggtheme = theme_bw()) + facet_grid(linear_update ~ algorithm, labeller = "label_both")
```
Especially for gmapping, the resulting plots seem non-normal.

```{r}
levene_test(avg_cpu_transformed ~ algorithm : linear_update, data = measurements)
```

```{r}
agg_measurements <- measurements %>% group_by(algorithm, linear_update) %>%
  get_summary_stats(avg_cpu_transformed, type = "mean_sd")
ggscatter(agg_measurements, "mean", "sd")
agg_measurements[order(agg_measurements$sd),]
```

The assumptions for Tukey's HSB test are not met. Hence, we resort to the non-parametric Dunn test.
*Note*: Dunn test assumes homogeneity of variance, but this does not seem to be the case (due to the outliers from gmapping).

```{r}
algorithm_linear_update_interaction <- interaction(measurements$algorithm, measurements$linear_update)
DunnTest(avg_cpu_transformed ~ algorithm_linear_update_interaction, measurements, method='BH')
```
